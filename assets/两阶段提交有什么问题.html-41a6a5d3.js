import{_ as i}from"./plugin-vue_export-helper-c27b6911.js";import{r as s,o as a,c as d,a as o,d as t,w as e,b as n,e as g}from"./app-f5dbfd30.js";const c={},_={class:"hint-container details"},p=o("summary",null,"本文内容",-1),u={class:"table-of-contents"},h=o("h2",{id:"_1-两阶段提交的问题",tabindex:"-1"},[o("a",{class:"header-anchor",href:"#_1-两阶段提交的问题","aria-hidden":"true"},"#"),n(" 1. 两阶段提交的问题")],-1),m={href:"https://aruni.me/studynotes/database/mysql/log/update%20%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.html",target:"_blank",rel:"noopener noreferrer"},b=g('<ul><li><p><strong>磁盘 I/O 次数多</strong>：在 “<strong>双一</strong>” 配置下，每次事务提交时，都需要先将 redo log 刷盘、然后再将 binlog 刷盘，这涉及到 <strong>两次刷盘</strong>；</p></li><li><p><strong>锁竞争激烈</strong>：两阶段提交虽然能保证「单事务」的两份日志的一致，但是在「多事务」情况下的两阶段提交过程中可能存在穿插进行，如果需要 <strong>保证某个事务在两个提交阶段的过程中不被别的事务插进来</strong>，就需要使用 <strong>锁</strong>。</p><blockquote><p>也就是经典的并发问题。</p></blockquote></li></ul><h3 id="_1-1-为什么磁盘-i-o-次数多" tabindex="-1"><a class="header-anchor" href="#_1-1-为什么磁盘-i-o-次数多" aria-hidden="true">#</a> 1.1 为什么磁盘 I/O 次数多？</h3><p>由于 redo log 和 binlog 都是先存储在内存中的，分别在 redo log buffer 和 binlog cache 中，所以对这两份文件的持久化时机十分重要。</p>',3),E={href:"https://aruni.me/studynotes/database/mysql/log/redo%20log%EF%BC%9A%E5%B4%A9%E6%BA%83%E6%81%A2%E5%A4%8D%E7%A5%9E%E5%99%A8.html#_4-redo-log-%E5%88%B7%E7%9B%98%E6%97%B6%E6%9C%BA",target:"_blank",rel:"noopener noreferrer"},f={href:"https://aruni.me/studynotes/database/mysql/log/binlog%EF%BC%9A%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%92%8C%E5%A4%87%E4%BB%BD.html#_4-binlog-%E5%88%B7%E7%9B%98%E6%97%B6%E6%9C%BA",target:"_blank",rel:"noopener noreferrer"},y=o("p",null,[n("先来说说，我们通常讲的 “"),o("strong",null,"双一"),n("” 配置是什么：")],-1),B=o("ul",null,[o("li",null,[n("在 redo log 进行事务提交时，有一个参数 "),o("code",null,"innodb_flush_log_at_trx_commit"),n("，当它设置为 1 时，表示每次事务提交时，都将 redo log 持久化到磁盘；")]),o("li",null,[n("在 binlog 进行事务提交时，也有一个参数 "),o("code",null,"sync_binlog"),n("，当它设置为 1 时，表示每次事务提交时，就将 binlog 持久化到磁盘。")])],-1),A=o("strong",null,"避免了日志丢失的风险",-1),k={href:"https://aruni.me/studynotes/database/mysql/log/update%20%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.html#_2-2-%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%B8%A4%E4%BB%BD%E6%97%A5%E5%BF%97%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7",target:"_blank",rel:"noopener noreferrer"},x=g('<p>但是，“双一” 配置带来这个好处的同时，也大大 <strong>增加了磁盘的 I/O 次数</strong>，降低了效率。</p><h3 id="_1-2-为什么锁竞争激烈" tabindex="-1"><a class="header-anchor" href="#_1-2-为什么锁竞争激烈" aria-hidden="true">#</a> 1.2 为什么锁竞争激烈？</h3><p>上面也说了，在「多事务」的情况下，两阶段提交不能保证两个阶段执行时不会被其他事务插进来，因此需要使用 <strong>锁</strong>，一个事务两阶段提交完成后，才能进行下一个。</p><p>在早期的 MySQL，通过使用 <strong><code>prepare_commit_mutex</code> 锁来保证事务提交的顺序，事务获取到该锁时，才能进入 prepare 阶段，直到 commit 阶段结束后，才能释放该锁</strong>。</p><p>因此，这样的加锁方式在 <strong>并发量较大</strong> 时，就存在 <strong>很激烈的锁竞争</strong>，效率是很低的。</p><h2 id="_2-binlog-的组提交" tabindex="-1"><a class="header-anchor" href="#_2-binlog-的组提交" aria-hidden="true">#</a> 2. binlog 的组提交</h2><p>MySQL 后续引入了 <strong>binlog 的组提交机制</strong>，用来解决上述的两个问题。具体来说，就是 <strong>把多个日志的刷盘操作合并成一个</strong>，从而 <strong>减少磁盘 I/O 次数</strong>。</p><p>那为什么要叫做组提交呢？注意提交这个字眼。其实是因为这个 <strong>合并的过程发生在 commit 阶段</strong>，也就是说，<strong>组提交没有改变 prepare 阶段</strong>，只是在 commit 阶段下了功夫。</p><p>具体来说，<strong>组提交把 commit 阶段又拆分为了三个阶段</strong>：</p><ul><li><strong>flush 阶段</strong>：多个事务按顺序将 binlog 从 binlog cache 写入文件（Page Cache），<strong>不刷盘</strong>；</li><li><strong>sync 阶段</strong>：对 binlog 文件做 fsync 操作，<strong>持久化到磁盘</strong>，这就 <strong>将多个事务的 binlog 合并成一次刷盘了</strong>；</li><li><strong>commit 阶段</strong>：各事务按顺序做 InnoDB commit 操作（将 redo log 置为 commit 状态）。</li></ul><p>在这三个阶段中，<strong>每个阶段都有一个对应的队列，每个阶段有锁进行保护，所以能保证事务的写入顺序，第一个入队的事务会成为 leader，leader 领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束</strong>。</p><p>这样每个阶段引入队列后，就可以 <strong>只针对每个队列加锁，而不是锁整个事务提交的过程</strong>。所以 <strong>锁的粒度更小，只用阻塞冲突的阶段，让更多阶段能并发的执行，从而提高了效率</strong>。</p><p>整体过程如下：</p><p><img src="https://run-notes.oss-cn-beijing.aliyuncs.com/notes/202303151851154.png" alt="" loading="lazy"></p><h2 id="_3-redo-log-的组提交" tabindex="-1"><a class="header-anchor" href="#_3-redo-log-的组提交" aria-hidden="true">#</a> 3. redo log 的组提交</h2><p>在 MySQL 5.6 的 binlog 组提交逻辑中，每个事务是各自执行 prepare 阶段的，也就是在此阶段各自将 redo log 刷盘，所以没法进行 redo log 的组提交。</p><p>在 MySQL 5.7 版本时，也引入了 redo log 的组提交，其实就是在 prepare 阶段做了一个优化：<strong>把 redo log 的刷盘延迟到 binlog 组提交的 flush 阶段</strong>，也就是把 prepare 和 flush 阶段融合了。</p><p>具体来说：</p><ol><li><p>在将新行更新到内存后，<strong>先不进行 redo log 的刷盘</strong>，而是将首个事务当作 Leader，<strong>将事务先按序添加进 flush 队列</strong>；</p></li><li><p>等 redo log 要进行刷盘的时候，<strong>再将 flush 队列中的事务组取出来，此时 Leader 就会将同组事务的 redo log 进行 write + fsync 刷盘</strong>（<strong>prepare 阶段</strong>）。</p><p>prepare 阶段结束后，然后 <strong>写入 binlog（flush 阶段），此时没有刷盘</strong>；</p><blockquote><p>可以看出，<strong>flush 队列用于支持 redo log 的组提交</strong>。</p></blockquote></li><li><p><strong>flush 阶段写入 binlog 后，会把事务组保存到 sync 队列，此时并不会马上刷盘</strong>，而是会 <strong>等一段时间</strong>，等待时间由参数 <code>binlog_group_commit_sync_delay = N(微妙)</code> 控制。</p><p>同时，还有一个参数 <code>binlog_group_commit_sync_no_delay_count = N</code>，用来 <strong>控制事务数量，如果事务数量达到了，则会无视时间参数，直接进行刷盘</strong>。</p><p>等待的目的都是为了 <strong>组合更多事务的 binlog</strong>，然后一起 <strong>刷盘</strong>（<strong>sync 阶段</strong>）；</p><blockquote><p>可以看出，<strong>sync 队列用于支持 binlog 的组提交</strong>。</p></blockquote></li><li><p><strong>sync 阶段后，会将完成刷盘的事务组保存到 commit 队列</strong>，最后进入 commit 阶段，<strong>从 commit 队列中获取事务组，调用引擎层的事务接口，将 redo log 设置为 commit 状态</strong>。</p><blockquote><p>此阶段的 <strong>commit 队列主要用于接收完成了 sync 阶段的事务</strong>，让 sync 队列可以更快的接收下一组事务。</p></blockquote></li></ol><p>整体过程如下：</p><p><img src="https://run-notes.oss-cn-beijing.aliyuncs.com/notes/202303152029193.png" alt="MySQL update + 两阶段提交的执行流程" loading="lazy"></p><h2 id="_4-关于日志刷盘的性能问题" tabindex="-1"><a class="header-anchor" href="#_4-关于日志刷盘的性能问题" aria-hidden="true">#</a> 4. 关于日志刷盘的性能问题</h2><p>由于组提交的加持，所以有时候会看到，明明磁盘的 I/O 能力（IOPS：每秒 IO 数量）也就两万左右，而 MySQL 的 TPS 却达到了两万，每秒就会写四万次磁盘（“双一” 配置：一次 TPS 需要刷两次盘，也就是两次 QPS），这就是组提交带来的效应。</p><p>另外如果发现 MySQL 在 <strong>IO 上出现了性能瓶颈</strong>，那么可以考虑通过如下方法解决：</p><ul><li>设置 <code>binlog_group_commit_sync_delay</code> 和 <code>binlog_group_commit_sync_no_delay_count</code> 参数，<strong>累计更多的事务后再进行 binlog 的刷盘</strong>，从而 <strong>减少 binlog 的刷盘次数</strong>；</li><li>设置 <code>sync_binlog</code> 为大于 1 的值 N（比较常见是 100~1000），即 <strong>每次提交事务都 write</strong>，但 <strong>累计 N 个事务提交时才进行 binlog 的刷盘</strong>。这样做的风险是，主机掉电时会丢 binlog 日志；</li><li>将 <code>innodb_flush_log_at_trx_commit</code> 设置为 2，<strong>把 redo log 的刷盘操作交给 OS</strong>。这样做的风险是，主机掉电的时候会丢数据。</li></ul><h2 id="_5-总结" tabindex="-1"><a class="header-anchor" href="#_5-总结" aria-hidden="true">#</a> 5. 总结</h2><p>由于 MySQL 需要 <strong>维护两份日志</strong>，一份来自 Server 层的 binlog，另一份来自 InnoDB 引擎层的 redo log，并且这两份日志都有先存储在内存中的，所以就要 <strong>保证刷盘时两份日志的逻辑一致性</strong>。</p><p>MySQL 首先通过 <strong>两阶段提交</strong> 来解决，但是带来的 <strong>问题</strong> 是：</p><ul><li>磁盘 I/O 次数多，效率低；</li><li>锁竞争激烈，性能低。</li></ul><p>为了解决上面的问题，MySQL 又提出了 <strong>组提交</strong>，现在支持 binlog 和 redo log 两者的组提交，主要做了如下改进：</p><ul><li><strong>让多个事务组成一组，再进行对应的刷盘</strong>，从而减少了磁盘 I/O 的次数；</li><li>组提交将 commit 阶段拆分成三个小阶段，每个阶段都由一个队列维护，加锁可以只对每个阶段加锁，从而 <strong>减小了加锁的粒度</strong>，让不同阶段的事务可以并发的执行，大大提高了性能。</li></ul><h2 id="_6-参考文章" tabindex="-1"><a class="header-anchor" href="#_6-参考文章" aria-hidden="true">#</a> 6. 参考文章</h2>',32),S=o("li",null,"《MySQL 实战 45 讲》",-1),I={href:"https://xiaolincoding.com",target:"_blank",rel:"noopener noreferrer"};function L(q,O){const r=s("router-link"),l=s("ExternalLinkIcon");return a(),d("div",null,[o("details",_,[p,o("nav",u,[o("ul",null,[o("li",null,[t(r,{to:"#_1-两阶段提交的问题"},{default:e(()=>[n("1. 两阶段提交的问题")]),_:1}),o("ul",null,[o("li",null,[t(r,{to:"#_1-1-为什么磁盘-i-o-次数多"},{default:e(()=>[n("1.1 为什么磁盘 I/O 次数多？")]),_:1})]),o("li",null,[t(r,{to:"#_1-2-为什么锁竞争激烈"},{default:e(()=>[n("1.2 为什么锁竞争激烈？")]),_:1})])])]),o("li",null,[t(r,{to:"#_2-binlog-的组提交"},{default:e(()=>[n("2. binlog 的组提交")]),_:1})]),o("li",null,[t(r,{to:"#_3-redo-log-的组提交"},{default:e(()=>[n("3. redo log 的组提交")]),_:1})]),o("li",null,[t(r,{to:"#_4-关于日志刷盘的性能问题"},{default:e(()=>[n("4. 关于日志刷盘的性能问题")]),_:1})]),o("li",null,[t(r,{to:"#_5-总结"},{default:e(()=>[n("5. 总结")]),_:1})]),o("li",null,[t(r,{to:"#_6-参考文章"},{default:e(()=>[n("6. 参考文章")]),_:1})])])])]),h,o("p",null,[n("在 "),o("a",m,[n("select 执行流程"),t(l)]),n(" 中，讲到了可以利用两阶段提交解决 redo log 和 binlog 一致性的问题。但是有两阶段提交有一个明显的问题，就是性能很差。主要体现在两个方面：")]),b,o("p",null,[n("在 "),o("a",E,[n("redo log"),t(l)]),n(" 和 "),o("a",f,[n("binlog"),t(l)]),n(" 中说过，它们的刷盘时机都有对应的策略，这里就不具体展开说了。")]),y,B,o("p",null,[n("可以发现，“双一” 配置极大程度的 "),A,n("。而且有一个崩溃恢复的逻辑需要依赖于 prepare 的 redo log，再加上 binlog 来恢复（见 "),o("a",k,[n("update 执行流程"),t(l)]),n("）。")]),x,o("ul",null,[S,o("li",null,[o("a",I,[n("小林 coding"),t(l)])])])])}const C=i(c,[["render",L],["__file","两阶段提交有什么问题.html.vue"]]);export{C as default};
